{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnFXDzcmj4iL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/ORDER_PROD_CUS_REV.csv\", encoding='utf-8')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_nS9MB7Wj6LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns = ['order_item_id', 'p_product_id', 'customer_id', 'review_id'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LefJEhy8j6I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
        "df['order_year'] = df['order_purchase_timestamp'].dt.year\n",
        "df['order_month'] = df['order_purchase_timestamp'].dt.month\n",
        "df['order_day'] = df['order_purchase_timestamp'].dt.day\n",
        "df['order_hour'] = df['order_purchase_timestamp'].dt.hour\n"
      ],
      "metadata": {
        "id": "ui7o2q0Lj6GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 계절 정보를 컬럼으로 추가\n",
        "# 봄 : 9, 10, 11, 여름 : 12, 1, 2, 가을 : 3, 4, 5, 겨울 : 6, 7, 8\n",
        "def get_season(month):\n",
        "    if month in [12, 1, 2]:\n",
        "        return 'Summer'\n",
        "    elif month in [3, 4, 5]:\n",
        "        return 'Autumn'\n",
        "    elif month in [6, 7, 8]:\n",
        "        return 'Winter'\n",
        "    else:\n",
        "        return 'Spring'\n",
        "\n",
        "df['season'] = df['order_month'].apply(get_season)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "eVFPFM_2j6DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['order_date'] = df['order_purchase_timestamp'].dt.date\n",
        "df['order_day_of_week'] = df['order_purchase_timestamp'].dt.dayofweek\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CaJFL6oxj6AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0: 주중, 1: 주말\n",
        "df['is_weekend'] = df['order_purchase_timestamp'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "drR6H4cvkDmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "practice_selected = ['order_date', 'product_category_name', 'season', 'is_weekend']\n",
        "practice_df = df[practice_selected]\n",
        "practice_df.head()"
      ],
      "metadata": {
        "id": "uyLnvTRDkDjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "practice_df['order_date'] = pd.to_datetime(practice_df['order_date'])\n",
        "\n",
        "demand_df = practice_df.groupby(['order_date', 'product_category_name', 'season', 'is_weekend']).size().reset_index(name='demand')\n",
        "\n",
        "demand_df.head(10)"
      ],
      "metadata": {
        "id": "pOPKe40akDgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "test_start_date = '2019-07-01'\n",
        "test_end_date = '2019-07-31'\n",
        "\n",
        "test_data = demand_df[(demand_df['order_date'] >= test_start_date) & (demand_df['order_date'] <= test_end_date)]\n",
        "\n",
        "# 2019년 7월 데이터 제거\n",
        "train_end_date = '2019-06-30'\n",
        "demand_df_filtered = demand_df[demand_df['order_date'] <= train_end_date]\n",
        "\n",
        "def map_season(season):\n",
        "    if season == 'Spring':\n",
        "        return 1\n",
        "    elif season == 'Summer':\n",
        "        return 2\n",
        "    elif season == 'Autumn':\n",
        "        return 3\n",
        "    elif season == 'Winter':\n",
        "        return 4\n",
        "    else:\n",
        "        return 0  # 예외 처리\n",
        "\n",
        "demand_df_filtered['season'] = demand_df_filtered['season'].apply(map_season)\n",
        "\n",
        "def is_weekend(date):\n",
        "    day_of_week = date.weekday()  # 0: 월요일, 6: 일요일\n",
        "    return 1 if day_of_week >= 5 else 0  # 토요일(5), 일요일(6)은 주말로 처리\n",
        "\n",
        "category_groups = demand_df_filtered.groupby('product_category_name')\n",
        "\n",
        "results = pd.DataFrame()"
      ],
      "metadata": {
        "id": "Z61mUJIxkDdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalers = {\n",
        "    'y': MinMaxScaler(feature_range=(0, 1)),\n",
        "    'season': MinMaxScaler(feature_range=(0, 1)),\n",
        "    'is_weekend': MinMaxScaler(feature_range=(0, 1))\n",
        "}"
      ],
      "metadata": {
        "id": "zSEXc-rZkt7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 타임 스텝 설정 (최근 날짜로부터 기간 정함)\n",
        "time_step = 365\n",
        "\n",
        "class DemandDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "for category, group in tqdm(category_groups, desc=\"Processing categories\"):\n",
        "    if category in test_data['product_category_name'].unique():  # 테스트 데이터셋에 해당 카테고리가 있는 경우에만 예측 수행\n",
        "\n",
        "        group = group.rename(columns={'order_date': 'ds', 'demand': 'y', 'season': 'season'})\n",
        "        group['is_weekend'] = group['ds'].apply(is_weekend)\n",
        "\n",
        "        features = group[['y', 'season', 'is_weekend']]\n",
        "        target = group['y']\n",
        "\n",
        "        features_scaled = features.copy()\n",
        "        for feature in features.columns:\n",
        "            features_scaled[feature] = scalers[feature].fit_transform(features[[feature]])\n",
        "\n",
        "        target_scaled = scalers['y'].fit_transform(target.values.reshape(-1, 1))\n",
        "\n",
        "        X = []\n",
        "        y = []\n",
        "        for i in range(len(features_scaled) - time_step):\n",
        "            X.append(features_scaled.iloc[i:i + time_step].values)\n",
        "            y.append(target_scaled[i + time_step])\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        if X.shape[0] == 0 or X.shape[1] == 0:\n",
        "            print(f\"Skipping category {category} due to insufficient data.\")\n",
        "            continue\n",
        "\n",
        "        dataset = DemandDataset(X, y)\n",
        "        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "        class LSTMModel(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size, num_layers):\n",
        "                super(LSTMModel, self).__init__()\n",
        "                self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "                self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "            def forward(self, x):\n",
        "                h_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n",
        "                c_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n",
        "                out, _ = self.lstm(x, (h_0, c_0))\n",
        "                out = self.fc(out[:, -1, :])\n",
        "                return out\n",
        "\n",
        "        input_size = X.shape[2]\n",
        "        hidden_size = 50\n",
        "        num_layers = 2\n",
        "        num_epochs = 10\n",
        "        learning_rate = 0.001\n",
        "\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = LSTMModel(input_size, hidden_size, num_layers).to(device)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        model.train()\n",
        "        for epoch in range(num_epochs):\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device).float()\n",
        "                labels = labels.to(device).float()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            if (epoch+1) % 10 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "        future_dates = pd.date_range(start='2019-07-01', end='2019-07-31', freq='D')\n",
        "        future = pd.DataFrame({'ds': future_dates})\n",
        "\n",
        "        future['season'] = 4\n",
        "        future['is_weekend'] = future['ds'].apply(is_weekend)\n",
        "\n",
        "        future_features = future[['season', 'is_weekend']]\n",
        "        future_features['y'] = 0  # 미래 데이터에 y를 0으로 설정\n",
        "        for feature in future_features.columns:\n",
        "            future_features[feature] = scalers[feature].transform(future_features[[feature]])\n",
        "\n",
        "        # 마지막 훈련 데이터로부터 미래 예측을 위한 입력 데이터 생성\n",
        "        future_X = []\n",
        "        last_train_data = features_scaled.iloc[-time_step:].values\n",
        "        for i in range(len(future_features)):\n",
        "            input_data = np.vstack([last_train_data, future_features.iloc[:i+1].values])[-time_step:]\n",
        "            future_X.append(input_data)\n",
        "\n",
        "        future_X = np.array(future_X)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            future_X_tensor = torch.tensor(future_X).to(device).float()\n",
        "            future_predictions = model(future_X_tensor)\n",
        "            future_predictions = future_predictions.cpu().numpy()\n",
        "            future_predictions = scalers['y'].inverse_transform(future_predictions)\n",
        "\n",
        "        future['product_category_name'] = category\n",
        "        future['order_date'] = future['ds']\n",
        "        future['demand'] = future_predictions\n",
        "        results = pd.concat([results, future[['order_date', 'product_category_name', 'demand']]])"
      ],
      "metadata": {
        "id": "vfAtzLsrkMlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.tail()"
      ],
      "metadata": {
        "id": "lo--m86TkMiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 날짜와 카테고리의 조합 생성\n",
        "all_dates = pd.date_range(start=test_start_date, end=test_end_date, freq='D')\n",
        "all_categories = test_data['product_category_name'].unique()\n",
        "all_combinations = pd.MultiIndex.from_product([all_dates, all_categories], names=['order_date', 'product_category_name']).to_frame(index=False)\n",
        "\n",
        "results = pd.merge(all_combinations, results, on=['order_date', 'product_category_name'], how='left')\n",
        "test_data = pd.merge(all_combinations, test_data, on=['order_date', 'product_category_name'], how='left')\n",
        "\n",
        "\n",
        "merged_results = pd.merge(results, test_data, on=['order_date', 'product_category_name'], how='inner')"
      ],
      "metadata": {
        "id": "EI1JQLxdj59X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "mae = mean_absolute_error(merged_results['demand_x'].fillna(0), merged_results['demand_y'].fillna(0))\n",
        "r2 = r2_score(merged_results['demand_x'].fillna(0), merged_results['demand_y'].fillna(0))\n",
        "rmse = mean_squared_error(merged_results['demand_x'].fillna(0), merged_results['demand_y'].fillna(0), squared=False)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R2) Score: {r2}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
      ],
      "metadata": {
        "id": "7jKrakFGk2f1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}